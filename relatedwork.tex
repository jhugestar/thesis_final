% !TEX root = thesis.tex

\chapter{Background}

The objective of this thesis is to endow machines with the social signal processing ability by which they can understand and use the kinesic signals (body languages)  of humans. This goal is hard to achieve without knowing how actually humans are performing it during the communication.  The problem is, however, our understanding on our own social signal ability is extremely limited, despite the long history of research to decipher this protocol, in many research field such as psychology, sociology, behavior science. The core idea of this thesis is motivated from the belief that the computational methods based on machine learning techniques with a large scale dataset can be the key to approach the solution where the protocol to process the social signals can be automatically learnt. In this section, the early work on human's kinesic signals (mostly non-computational methods) are discusses and more recent work to tackle the problem based on the computational methods are explored. Notably, the most of the previous computational methods are limited to relatively simple setup (dyadic motion, focusing faces, seating position), due to the lack of social signal measurement methods to extend the scope. The  social signal measurement system and method presented in this thesis are based on the cutting-edge techniques covering computer vision, computer graphics, and machine learning technqiues, and the related previous work is also discusses. 


Nonverbal communication is categorized into subfields, including kinesics (body language), proxemics (distance),  physical appearance,  vocalics,  and haptics (touch) \cite{}. Among them, this thesis mainly focuses on kinesics and proxemics. Hall first introduced the concept of proxemics to describe how humans use their personal space during communication~\cite{Hall66}, and similarly Kendon studied spatial and orientational formations (named F-formation) established when multiple people communicate in a common space~\cite{kendon90}. Birdwhistell presented the term ``kinesics" to refer to the study of face and body movements of human in communication~\cite{Birdwhistell52, ekman1969}. Among them, facial expressions have been gained most of the attentions by researchers. Ekman pioneered the study of relation between emotions and facial expressions, and best known for the Facial Action Code System (FACS), a system to describe facial expressions using combinations of atomic units (Action Units)~\cite{ekman1977facial}. Since then, this system remains a standard to annotate and measure facial expressions, making a broad impact in various fields. Body gestures is relatively poorly explored area compared to the face, although multiple researchers address the importance of body languages in communications~\cite{Gelder09, Moore13, Meeren-2005, Aviezer-2012}. 


Surprisingly the study for nonverbal communication is still in its infancy despite the large attention of the fields, and the approaches proposed several decades ago are still the most widely used methods available~\cite{Moore13}. A core obstacle hindering the advance of the fields is the fact that the objective of the research goal is ambiguous. In the perspective of robotics and artificial intelligence, the main goal of exploring this field is to build a machine to use this ability to genuinely interact with human. Unfortunately, this goal is really far from the current technology. The subtle details cannot be objectively analyzes without the proper measurmenet tools which has been missing so far. Due to the reason, most of the previous research haven't extract meaningful output to be conveyed to building socially interacting machines. Then what kind of fields are  studies?



One of the most objectively studies area is proxemics and F-formation. These fields are related to low dimensional features humans are making (at most 3 dimenstion for the location and  2 dimension for the orientation). It is possible to build the model for this and also it is possible to demonstrate the theory  by simple setup with even manual measurement. Hall piorneered this study and built the initial theory. Recently, computational methods using computer vision studies automatically finds groups, and HRI applications. 




Face is another area where the model manually defined works still well. FACS are defined by Paul Ekman and his colleagues and since then this model has been used in many fields.  It is still the dominant method in computational methods and modeling.  TODO: FACS related hand coding system and computational method





P. Ekman and W. Friesen. Facial action coding system: A
technique for the measurement of facial movement. Consulting
Psychologists Press, 1978.




Automatic FACS detection:
Much effort
in automatic facial image analysis seeks to automatically
recognize FACS action units [12, 20, 25, 27].

G. Littlewort, M. Bartlett, I. Fasel, J. Susskind, and J. Movellan.
Dynamics of facial expression extracted automatically
from video. Image and Vision Computing, 24(6):615–625,
2006.

M. Pantic and L. Rothkrantz. Facial action recognition for facial
expression analysis from static face images. IEEE Transactions
on Systems, Man, and Cybernetics, pages 1449–
1461, 2004.

 Y. Tian, J. F. Cohn, and T. Kanade. Facial expression analysis.
In S. Z. Li and A. K. Jain, editors, Handbook of face
recognition. New York, New York: Springer, 2005.

Y. Tong, W. Liao, and Q. Ji. Facial action unit recognition by
exploiting their dynamic and semantic relationships. Transactions
on Pattern Analysis and Machine Intelligence, pages
1683–1699, 2007

Tomas Simon∗
, Minh Hoai Nguyen∗
, Fernando De La Torre, Jeffrey F. Cohn 
Action Unit Detection with Segment-based SVMs


Comprehensive database for facial expression analysis

T Kanade, Y Tian, JF Cohn - fg, 2000 - computer.org


Automatic facial expression analysis: a survey


Early work of auto face emotional express recognition
M. Suwa, N. Sugie, and K. Fujimora, “A Preliminary Note on Pattern Recognition of Human Emotional Expression,” Proc. Int’l Joint Conf. Pattern Recognition, pp. 408-410, 1978








%The face is a powerful channel of nonverbal communication.
Facial expression provides cues about emotional response,
regulates interpersonal behavior, and communicates
aspects of psychopathology. To make use of the information
afforded by facial expression, Ekman and Friesen [8] proposed
the Facial Action Coding System (FACS). FACS is
a comprehensive, anatomically-based system for measuring
all visually discernible facial movement. It segments all facial
activity on the basis of 44 unique “action units” (AUs),
as well as several categories of head and eye positions an




Face model also connected other studies such as person-person interaction (baby mother), and sentimental analysis to know the target subject facial expression.  TODO: this area.

Infant-mother face-to-face interaction: Age and gender differences in coordination and the occurrence of miscoordination
EZ Tronick, JF Cohn
Child development, 85-92








Kinesics and body languages are relatively less explored. The main problem is the limited way to describe the motion. Several method tried to build Action units for bodies, but they are not well defined yet. the amount of body data is limited. The way to capture body during the motion capture is limited. But still there are trials. 

Sentimental analysis
Synchrony?
Classficiation??



Computational method area.

Affective computation. 


Social Signal Processing.


Alex pentland
Morency. 
Social Robotics.



The fundamental limitation of this study is a lack in measuring the data, and without it it is extremely hard to build or demonstrate models and theory.  
Language was there. Face was there. What about body??


Computer vision/graphics has made a great progress. Now this is the time. 


Body measurement method.

Body modeling


There has been computational approahces to tackle this problem. These are based on sensing rather than observation study or manual coding scheme.  But mainly they are focus on faces (since mostly sensing face is easier). Their scenarios are extremely limited. 
	




Now we hope to expand the whole idea for entire body. we know we can use all bodies. Without including this signals, our answer should be misleading. Fortuantely, this is the time that this type of research can be possible. Good sensors are available. Good measurement thechnique can be possible. There exist a nice model to incorporate all this.  


















Kinesic signals play a crucial role in human social communication, and, due to its important role in communication, nonverbal communication has received a lot of attentions by psychologies.  Since the goal of Artificial Intelligence is to mimic human's intelligence, and the social intelligence is also an important factor to be considered. In that sense, it is worth looking back the history of work in pychology where understanding kinesic signal has been tried 








Historically, Mehrabian found in his research that more than 93 percent of emotional meaning is transmitted nonverbally~\cite{Mehrabian67,Mehrabian81}. Birdwhistell~\cite{Birdwhistell70} further asserted that nonverbal communication accounts for approximately two-thirds of what we communicate. Although there exist controversy regarding the quantification of the relative importance of nonverbal signals, it is still widely accepted by researchers that nonverbal signals have more impact than the verbal part in communications~\cite{Moore13}.





If we define the social signals are the channels we put various messages (word, emotion, intention and so on ) for communication, then basically all possible signals -- voice, vocal tones, facial expression, finger motion, body location, and body orientations -- can be a part of the signals.   Language should be the most studied field, and in this thesis we focus on the nonverbal parts. Researchers categories this into several subcatetories, including including Proxemics, Kinesics, Vocalics, and Haptics. This thesis is more related to the visual cues which can be captured by camera sensors, so mostly related to the Proxemics and Kinesics. 

The interest of this field has been there for centuries. The research has been mostly lead by pychology or cognitive sciences. The field has been gained the attention from roboticist and computer scientist who wish to build a machine or robot which can genuinely interact with humans.  In the end, we have to know the communicative protocol humans are using first, to equip the ability to machines, and this makes that it is worth taking a look at the work done in other field. At the same time, there exist interesting thought that probably we can simply throw away all previous method. We can see the similar consequence in the language field. It has been prooved that without any complicated rules or grammar linguist have been built for centuries are not required to build machine to use the langues -- understand human's language, use it, and translate to other languages. Current success is most leveraged by data itself. The rules, patterns, features are just automatically discovered and extracted by machine learning techniques from the large scale dataset. 

Basically we want to get the answer from the similar thought for body languages. Surely this data driven approach should be more suitable to the body language part since, compared to verbal counter part, we have been failed to build any rules and grammars for the body languages yet. This means it is challenging, but maybe this data driven and computational methods should be the right direction to solve this problem. 

What would be the major obstacle? Data! Compared to the tons of language data, nonverbal body language data is less available. We may consider images and videos, but they are really raw data which is hard to directly processing for "extracting the rules for social signals", because baisically they are pixels as a raw format, and we need to extract scemantic meanings out of that. And, as you know, this is the fundamental goal of all computer vision fields, and this means that we need to solve computer vision problem first to tackle the target problem. 

But still there are similar approached to tackle the problem with available technology and methods. Most of them are more focused on the face part (since there were practically working already up to some level). In this paper, we will explore exisisting trials in the similar track. 



Social Signal Processing is one of the term to refer to the similar track --- using computational method to understand social signals. A good review paper is also available. And good conferences ICMI, virtual humans are there. 




Several aspect of interpersonal non-verbal signals have been studied, and they are often restricted by existing measurement techniques. 


Non-computational methods are dependent to the human coder who describe or annotate specific or global event of the interaction. As expected the annotation tends to be subject, cannot capture enough details, and not easy to be scale. 


Computational methods have been tried, but mostly on the face. Face-to-face interaction between doctor-patient, mother-baby, negotiation, and so on. Most of them are on the static or table setup so that cameras or sensors can focus on the target part. 




Computational method for the bodies are extremely limited. Total body are extremely limited. Why is it limited? Any solution?



Building dataset is challenging. Needs several experts [Sun 2011]. 
There are dataset [Sun 2011, face DBs, salsa and so on]. 

Annotation? unclear..


Interaction vs Psudointeraction










But this field often considered very limited scenarios. For example, negotiation, sentimental analysis, and so on. And each field defined the task and evaluation method by themselved. Unfortuatnly, the output of a result is hardly generalizable and different setup requires to build a different theory or method. 




Formation, Proximics can be one since they are easier to measure. 


Synchrony and mimicary is another one



Turn taking, gestures, emotion recognition and so on. 	


interaction is a dynamic process between people exchanging or coordinating signals

Mother infant interaction

Mostly dyad, triad and polyad are rare

Establishing rapport (machine is connected to the human and they feel that they are on the same page)






Specific focus on faces. 



What about body??

 




This chapter reviews related work in capturing and modeling kinesic signals in social interactions. While nonverbal communication in general includes all types of ``other-than-words" communication channels including Proxemics, Kinesics, Vocalics, and Haptics, in this thesis we use this term to refer to the communication by kinesic signals. 




Pychology? 

What is the social interaction?

Synchrony, mimicary?


What is the traditional method? Coding. User study....  What is the limitation?


Coding Interactive Behavior(CIB)

What is the current conclusion? 


Often dyadic. Hard to triadic. 


Any background for the computational method??



What is the scope ? definition of my social signal processing?


signals are subtle. previous measurements are too coarse.

%Computational Analysis for Social Signals

Faces

Bodies


Synchrony Review paper. 
Social Signal Processing review paper 


%How can we represent social interection


\section{Cognitive Science}
Theory of mind

\section{Psychology}
Theory of mind


\section{3D Motion Capture}
Theory of mind (model-based)


Information theory, Mutual Information?

\section{Action Classfication}


\section{Human Body Modeling}
Theory of mind



\section{Body Motion Understanding}
Theory of mind


\section{Early Work In Understanding Social Interaction}

Due to its important role in communication, nonverbal communication has received a lot of attentions by researchers. Historically, Mehrabian found in his research that more than 93 percent of emotional meaning is transmitted nonverbally~\cite{Mehrabian67,Mehrabian81}. Birdwhistell~\cite{Birdwhistell70} further asserted that nonverbal communication accounts for approximately two-thirds of what we communicate. Although there exist controversy regarding the quantification of the relative importance of nonverbal signals, it is still widely accepted by researchers that nonverbal signals have more impact than the verbal part in communications~\cite{Moore13}.

Nonverbal communication are often categorized into subfields. Hall first introduced the concept of proxemics to describe how humans use their personal space during communication~\cite{Hall66}, and similarly Kendon studied spatial and orientational formations (named F-formation) established when multiple people communicate in a common space~\cite{kendon90}. Birdwhistell presented the term ``kinesics" to refer to the study of face and body movements of human in communication~\cite{Birdwhistell52, ekman1969}. Among them, facial expressions have been gained most of the attentions by researchers. Ekman pioneered the study of relation between emotions and facial expressions, and best known for the Facial Action Code System (FACS), a system to describe facial expressions using combinations of atomic units (Action Units)~\cite{ekman1977facial}. Since then, this system remains a standard to annotate and measure facial expressions, making a broad impact in various fields. Body gestures is relatively poorly explored area compared to the face, although multiple researchers address the importance of body languages in communications~\cite{Gelder09, Moore13, Meeren-2005, Aviezer-2012}. Surprisingly study for nonverbal communication is still in its infancy, and the approaches proposed several decades ago are still the most widely used methods available~\cite{Moore13}. 

Cameras have been used as a tool to record and study social interaction. Even Darwin, in his foundational treatise on the expression of emotion, used photographs to prompt participant response to expressions~\cite{Darwin-1872}. Since then, photographs have been--and continue to be--a fundamental tool in studying social behavior~\cite{Hall-1962,Izard-1971,Ekman-1977}. When the video camera was invented, it too became an integral tool to study the dynamics of social interaction~\cite{Muybridge-1887,Yarbus-1967}. In most of the work, however, the rerecorded scenes are analyzed by human annotators requiring them to spend an enormous amount of time. More importantly, the observer-based annotation system is subject to bias despite efforts to make annotation guidelines, and subtle details in nonverbal signals are ignored due to the limitation in representing them by manual annotations. 


\section{Computationally Modeling Kinesic Signals}
Over the last decade, there has been increasing interests in computationally analyzing nonverbal communication by measuring signals via computer vision techniques.  Analyzing facial expression is one of the core examples~\cite{ChuDC13, Torre15, shan2009facial}. Other literatures present methods to automatically detect social cues from photos and videos, including detecting F-formation~\cite{setti2015f}, recognizing proxemics~\cite{yang2012recognizing}, recognizing emotions by body pose\cite{schindler2008recognizing}, and detecting social saliency~\cite{park20123d}. Affective Computing has also been growing up rapidly, where video cameras and other sensor measurements (EMG, electrodermal skin response, and heat rate) are used with computer vision and machine learning techniques to analyze emotion, social behavior, and roles~\cite{picard1997affective} in social interaction. 

%Dataset
The availability of large scale data is essential in computational analysis of social interaction. The AMI Meeting Corpus is one of the most extensive database containing group interactions, but only contains a contrived table meeting scenarios with limited number of views~\cite{carletta2005ami}. Several other datasets recording unstructured social scenes have also been presented, where multiple people (from 5 to 14 subjects) naturally communicate without restrictions in their behavior~\cite{Zen-10,Cristani-11,SALSA-15}. In contrast to the scenes captured in structured environment such as round-table meetings~\cite{carletta2005ami, Lepri-12}, the subjects in such unstructured environments show richer social signals in their body motion, locations, and orientations. However, due to the unconstrained nature, it is challenging to measure body motion of subjects, and, thus, relatively low dimensional signals (e.g., quantized body/head orientation) often are considered. None of the previous work addresses to reconstruct full body skeletal motion of individuals in social situations.



\section{Automatically Measuring 3D Kinesic Signals}

In computer vision, there have been a large number of approaches to measure 3D structure and motion of dynamically moving people using multiple camera sensors. Kanade et al.~\cite{Kanade-1997} pioneered the use of multi-view sensing systems to ``virtualize" reality, using 51 cameras mounted on a geodesic dome of 5 meters in diameter. A number of systems were subsequently proposed to produce realtime virtualizations~\cite{Matusik-2000,Matsuyama-2002,Gross-2003,Petit-2009}. Vlasic et al.~\cite{Vlasic-2009} recovered detail by applying multi-view photometric stereo constraints using a system with 1200 lights on a dome and eight cameras. More recently, a multimodal multi-view stereo system fusing 53 RGB cameras and 53 infrared cameras has been proposed to reconstruct high quality 3D virtual characters~\cite{Collet-15}. 

Methods explicitly tackle markerless motion capture by producing 3D skeletal structures over time similar to their marker-based counterparts~\cite{Gall-09, Gavrila-96, Cheung-05,Plankers-03, Bregler-04, Kehl-06, Corazza-10, Vlasic-08, Brox-10, Stoll-11, deAguiar-2008, Vlasic-2008, Furukawa-2008}. The methods deform pre-defined articulated templates of fixed topology to recover the details that were subsampled or occluded in the set of views at a time instant. These methods require an offline method to generate a rigged 3D model for each individual, and the quality of the template is important to achieve high accuracy. The template models need to be aligned at the initial frame to be tracked, and usually a predefined pose (such as a T-pose) are assumed and performed by all individuals. The methods in this area fundamentally suffer from topological changes restricted by the template model, and, similar to other tracking methods, error accumulation is a critical issue in tracking for long durations. Although the 3D template-based method shows good performance---and has become a standard in markerless motion capture approaches---the requirement of a high quality 3D template for each individual limits the practicality of the method, especially in our scenario where dozens of individuals are involved, as the method does not scale well to multiple people. Previous work is demonstrated on a single actor with few exceptions \cite{Ye-2012, Liu-2013}. For example, it is required to segment image cues per subject to track them independently as in~\cite{Liu-2013}, which becomes more complicated if a large number of people are involved, as in our scenes. It should be noted that none of the previous markerless motion capture approaches focus on capturing non-verbal social behaviors of multiple naturally interacting people.




 %such challenging scenarios, although rich social signals are embedded in those subtle motions. 
%
%\section{Human Motion Prediction}
%Predicting future human motion is an emerging area in computer vision and machine learning. Researchers propose approaches of predicting pedestrian's future trajectory~\cite{kitani2012activity}, forecasting human interaction in dyadic situations~\cite{huang2014action}. More recently, Deep Neural Network are used to predict future 3D motion from motion capture data~\cite{mnih2012conditional, Fragkiadaki_2015_ICCV, jain2016structural}, but they only focus on single subject's motion. A few literatures address point motion trajectory prediction in social situations~\cite{helbing1995social, alahi2016social}.

%
%\section{Human Pose Detection in 2D Images}
%%\subsection{Single View Pose Detection and Application in Multi-View}
%
%Over the last few years, single view 2D pose estimation method shows great advances based on Convolutional Neural Network framework with large scale human pose datasets~\cite{Tompson-14,Wei-2016}. The state-of-the-art method~\cite{Wei-2016} shows an excellent performance in various environments with varying subject's shape, appearance, and scales. Recently, a few methods facilitate body pose detectors in multiple views to reconstruct 3D body poses~\cite{Burenius2013, Amin-13, Belagiannis2014, Elhayek-15, Elhayek-16}. To infer 3D skeletal parameters from 2D pose detection cues, unary and pairwise terms are defined based on the pre-training data of joint length, relative joint angles, and body colors. The methods are performed at each time independently in fewer camera setting, and thus they typically suffer from motion jitter. Although the results show potential in general environment settings (e.g., outdoors), the methods in this category do not yet reach similar quality compared to the 3D template-based approaches. % Rather, they aim less challenging scenes in more general settings, which is opposite to the direction of our scenarios. 
%





%Depth sensors such as the Kinect~\cite{Shotton2011,Baak2011} are also emerging as a promising sensing modality. The main advantage of this sensor is that it can produce 3D pose from a single view. However, this approach to body pose recognition directly interferes with social interaction: the Kinect requires people to stand facing towards the sensor to get reasonable results. Using multiple Kinects has potential~\cite{Ye-2012} in that it may produce dense point cloud easily, but how to fuse them for 3D pose estimation has not been explored thoroughly. %, and more importantly, synchronization among Kinects is inherently challenging in the current system specification. 



%
%%In practice, more views are required to obtain accurate 3D reconstructions. All of the previous work use a few cameras, and they use pre-trained 3D priors such as bone length, joint

%
%How to collect and measure nonverbal signal data is important to pursue a data-driven approach for the goal. However, only few dataset contains socially interacting groups with limited measurements ~\cite{alameda2016salsa, mccowan2005ami, lepri2012connecting}. The scene of the sequences are often a table setup limiting free body movement and capturing upper body only, or limited resolution from distances focusing only people's body locations and coarse orientations. Other datasets provide rich 3D body motion information by motion capture techniques but only for single subjects\cite{gross2001cmu, h36m_pami, sigal2010humaneva}. More recently, full body motion capture data of interacting groups using a large number of camera system is proposed for social interaction captures~\cite{Joo-15}. This work shows great potential in collecting a large scale social interaction data without priming in contrast to motion capture techniques. 
%




%On the other hand, marker-less motion capture has been extensively studied for last decade in computer vision area~\cite{Gall-09, Gavrila-96, Cheung-05,Plankers-03, Bregler-04, Kehl-06, Corazza-10, Vlasic-08, Brox-10, Stoll-11}. The researches aim to achieve similar performance to their marker-based counterparts to overcome the limitation of attaching markers on the target subjects. Although the marker-less nature is also the core in capturing social signaling addressed in this paper, in contrast to the focus of psychology community, previous work in this domain mainly focus on capturing motion of single individuals with few exceptions~\cite{Elhayek-15, Liu-2013}, and, more importantly, the methods have never been applied to capture the non-verbal cues of communicating multiple people. In previous methods, smaller number of cameras (less than 15) are used and strong model priors which usually represented as 3D model templates (articulated skeletons with shape/color priors) are used to overcome the ambiguities caused by the limited views. It is obvious that the problem becomes much more challenging, if multiple subjects are captured by such small number of views, and stronger priors about the scene are needed (e.g., a rigged 3D model generated by laser scanning for accurate 2D segmentation as in~\cite{Liu-2013}. However, relying on the strong model prior is not suitable in our scenario where tens of subjects should be participated for social study and, more importantly, any potential bias affecting their naturalism should be avoided. In ideal, the method need to capture the scene with minimum interference without requiring any laborious model building step and without instructing them to perform a pre-defined posture to align or initialize the model during the capture (e.g., imagine how hard it is if we capture the interaction between a toddler and his/her mom as in one of our example). It should be also noted that the people's motion usually seen during the social interactions are distinctive from the scenes (e.g., jumping, dancing, and acrobatic motions) usually demonstrated in the previous work. For example, the frequently occurred poses in our dataset as shown in Figure~\ref{fig:iconicPoses} have lots of topological changes and severe self occlusions where the template model based tracking method mainly suffer from. That is, more challenging problems, capturing motions of multiple people without limiting their motion, should be addressed with minimum interference (no 3D template model building stage and no requirement of performing canonical posture for initialization). 
%While the major stream of previous work aim the direction to use smaller number of cameras or even single view depth camera for single individual's less socially informative motion, our approach pursues the other direction which has not been explored yet: capturing social signals of interacting multiple people with least constraint to them (ideally prior free), but instead using unlimited system power. 





%\section{Measuring Nonverbal Signals}
%\begin{itemize}
%	\item Psychology and Sociology
%		\subitem Temperature
%		\subitem Electronic signal (skin or brain)
%		\subitem electrocardiogram, electromyogram, skin conductivity,respiration [Healey and Picard 2004]
%		\subitem Eye tracking
%		\subitem Face detector
%	\item Machine Learning, Affective computing, Multi modality, Virtual agent
%		\subitem Face detector 
%		\subitem Body detector
%		\subitem Manual orientation
%	\item Computer vision and Graphics
%		\subitem Multiview system
%		\subitem Markerless motion capture (multi subjects)
%		\subitem Face capture
%	\item Our contribution
%		\subitem multiple people
%		\subitem any orientation
%		\subitem minimum restriction
%		\subitem subtle details
%\end{itemize}
%
%\section{Predicting Nonverbal Signals}
%\begin{itemize}
%	\item Psychology and Sociology
%			\subitem ???
%	\item Machine Learning, Affective computing, Multi modality, Virtual agent
%			\subitem F-formation detection
%			\subitem Leader detection. sentiment analysis, happinesss...
%	\item Computer vision and Graphics
%			\subitem Hyun soo's 
%			\subitem Activity forecasting
%			\subitem Katarighna, Structured RNN, Feng's 
%	
%\end{itemize}
%

%
%\section{Automated Group Behavior Analysis}
%Over the last decade, there has been increasing interest in automatically analyzing multiple people's social interaction using multiple camera sensors. Several datasets recording unstructured social scenes are presented, where multiple people (from 5 to 14 subjects) naturally communicate without restriction in their behavior~\cite{Zen-10,Cristani-11,SALSA-15}. In contrast to the scenes captured in structured environment such as round-table meetings~\cite{Lepri-12}, the subjects in such unstructured environments show richer social signals in their body motion, locations, and orientations. However, due to the unconstrained nature, it is challenging to measure their body motion because of severe occlusions among people. Thus, the previous work in this area usually aims to get coarse level of measurement (e.g., quantized body/head orientation), and they rather focus on higher level social understanding from the coarse measurements, such as F-formation detection~\cite{Lepri-12} and personality predictions~\cite{SALSA-15,Zen-10}. None of the previous work in this domain addresses to reconstruct full body skeletal motion of individuals in such challenging scenarios, although rich social signals are embedded in those subtle motions. 
%
%%On the other hand, marker-less motion capture has been extensively studied for last decade in computer vision area~\cite{Gall-09, Gavrila-96, Cheung-05,Plankers-03, Bregler-04, Kehl-06, Corazza-10, Vlasic-08, Brox-10, Stoll-11}. The researches aim to achieve similar performance to their marker-based counterparts to overcome the limitation of attaching markers on the target subjects. Although the marker-less nature is also the core in capturing social signaling addressed in this paper, in contrast to the focus of psychology community, previous work in this domain mainly focus on capturing motion of single individuals with few exceptions~\cite{Elhayek-15, Liu-2013}, and, more importantly, the methods have never been applied to capture the non-verbal cues of communicating multiple people. In previous methods, smaller number of cameras (less than 15) are used and strong model priors which usually represented as 3D model templates (articulated skeletons with shape/color priors) are used to overcome the ambiguities caused by the limited views. It is obvious that the problem becomes much more challenging, if multiple subjects are captured by such small number of views, and stronger priors about the scene are needed (e.g., a rigged 3D model generated by laser scanning for accurate 2D segmentation as in~\cite{Liu-2013}. However, relying on the strong model prior is not suitable in our scenario where tens of subjects should be participated for social study and, more importantly, any potential bias affecting their naturalism should be avoided. In ideal, the method need to capture the scene with minimum interference without requiring any laborious model building step and without instructing them to perform a pre-defined posture to align or initialize the model during the capture (e.g., imagine how hard it is if we capture the interaction between a toddler and his/her mom as in one of our example). It should be also noted that the people's motion usually seen during the social interactions are distinctive from the scenes (e.g., jumping, dancing, and acrobatic motions) usually demonstrated in the previous work. For example, the frequently occurred poses in our dataset as shown in Figure~\ref{fig:iconicPoses} have lots of topological changes and severe self occlusions where the template model based tracking method mainly suffer from. That is, more challenging problems, capturing motions of multiple people without limiting their motion, should be addressed with minimum interference (no 3D template model building stage and no requirement of performing canonical posture for initialization). 
%%While the major stream of previous work aim the direction to use smaller number of cameras or even single view depth camera for single individual's less socially informative motion, our approach pursues the other direction which has not been explored yet: capturing social signals of interacting multiple people with least constraint to them (ideally prior free), but instead using unlimited system power. 
%
%
%\section{Markerless Motion Capturing Using Multiple View Systems}
%%To avoid potential interference on the social signaling, it is essential to measure the scene non-intrusively, for example without using explicit retro-reflective marker with black tight suit or attaching inertial sensors on the subject's body. 
%
%%Besides RGB cameras, motion capture methods provide precise dynamics measurements and have also been used to study social behavior~\cite{McDonnell-2008}, despite the interference caused by markers on social signaling. 
%
%In computer vision, there has been a large number of approaches to measure 3D structure and motion of dynamically moving people using multiple camera sensors. Kanade et al.~\cite{Kanade-1997} pioneered the use of multi-view sensing systems to ``virtualize" reality, using 51 cameras mounted on a geodesic dome of 5 meters in diameter. A number of systems were subsequently proposed to produce realtime virtualizations~\cite{Matusik-2000,Matsuyama-2002,Gross-2003,Petit-2009}. Vlasic et al.~\cite{Vlasic-2009} recovered detail by applying multi-view photometric stereo constraints using a system with 1200 lights on a dome and eight cameras. More recently, a multimodal multi-view stereo system fusing 53 RGB cameras and 53 infrared cameras has been proposed to reconstruct high quality 3D virtual characters~\cite{Collet-15}. 
%
%Other methods explicitly tackle the markerless motion capture by producing 3D skeletal structures over time similar to the marker-based counterparts~\cite{Gall-09, Gavrila-96, Cheung-05,Plankers-03, Bregler-04, Kehl-06, Corazza-10, Vlasic-08, Brox-10, Stoll-11, deAguiar-2008, Vlasic-2008, Furukawa-2008}. The methods deform pre-defined articulated templates of fixed topology to recover the details that were subsampled or occluded in the set of views at a time instant. These methods require an offline method to generate a rigged 3D model for each individual, and the quality of the template is important to achieve high accuracy. The template models need to be aligned at the initial frame to be tracked, and usually a predefined pose (such as a T-pose) are assumed and performed by all individuals. The methods in this area fundamentally suffer from topological changes restricted by the template model, and, similar to other tracking methods, error accumulation is a critical issue in tracking for long durations. Although the 3D template-based method shows good performance---and has become a standard in markerless motion capture approaches---the requirement of a high quality 3D template for each individual limits the practicality of the method, especially in our scenario where dozens of individuals are involved, as the method does not scale well to multiple people. Previous work is demonstrated on a single actor with few exceptions \cite{Ye-2012, Liu-2013}. For example, it is required to segment image cues per subject to track them independently as in~\cite{Liu-2013}, which becomes more complicated if a large number of people are involved, as in our scenes. It should be noted that none of the previous markerless motion capture approaches focus on capturing non-verbal social behaviors of naturally interacting multiple people.
%
%%In contrast, our method is designed to be free from the above limitations. Our method does not rely on the predefined 3D template but based on the detection and motion cue to reconstruct the people's motion without prior assumptions about the scene and individuals: the scene may have arbitrary number of people; people can be of any shape and appearance (children to adults, small to tall, and arbitrary clothing);  No template calibration or alignment is needed allowing people to leave or participate during the interaction; motion is not restricted and free from topological constraints. Neither background subtraction nor a segmentation is required. %Our dataset contains multiple people's natural interactions (up to 8), and people performs any challenging natural motion without constrains (crossing arms, chin on a hand, and so on). 
%
%%, and reconstruct the 3D body motion of arbitrary number of people directly from multiple views. Our method well fits to the goal of social study where large number of subjects are studied (to avoid the need of making many predefined model) and subject are present and leave freely (to avoid the need of model alignment).
%
%%A number of approaches presented techniques to optimize free-viewpoint exploration of dynamic scenes  ~\cite{Carranza-2003,Zitnick-2004,Nobuhara-2004,Matusik-2004,Wilburn-2005,Vedula-2005}. These techniques used a variety of proxies of varying accuracy and used as few as eight \cite{Zitnick-2004} and as many as 128 \cite{Wilburn-2005}. 
%%As another direction, multi-camera array systems have been proposed to create virtual sensors to capture light fields of the scene [Levoy, Zitnik] for various application in computational photography (high resolution and High-Dynamic Range, Synthetic Aperture) and graphics (space-time interpolation).  
%%http://old.siggraph.org/publications/2006cn/course07.pdf
%
%\subsection{Pose Detection Based Approach}
%%\subsection{Single View Pose Detection and Application in Multi-View}
%
%%Depth sensors such as the Kinect~\cite{Shotton2011,Baak2011} are also emerging as a promising sensing modality. The main advantage of this sensor is that it can produce 3D pose from a single view. However, this approach to body pose recognition directly interferes with social interaction: the Kinect requires people to stand facing towards the sensor to get reasonable results. Using multiple Kinects has potential~\cite{Ye-2012} in that it may produce dense point cloud easily, but how to fuse them for 3D pose estimation has not been explored thoroughly. %, and more importantly, synchronization among Kinects is inherently challenging in the current system specification. 
%
%Over the last few years, single view 2D pose estimation method shows great advances based on Convolutional Neural Network framework with large scale human pose datasets~\cite{Tompson-14,Wei-2016}. The state-of-the-art method~\cite{Wei-2016} shows an excellent performance in various environments with varying subject's shape, appearance, and scales. Recently, a few methods facilitate body pose detectors in multiple views to reconstruct 3D body poses~\cite{Burenius2013, Amin-13, Belagiannis2014, Elhayek-15, Elhayek-16}. To infer 3D skeletal parameters from 2D pose detection cues, unary and pairwise terms are defined based on the pre-training data of joint length, relative joint angles, and body colors. The methods are performed at each time independently in fewer camera setting, and thus they typically suffer from motion jitter. Although the results show potential in general environment settings (e.g., outdoors), the methods in this category do not yet reach similar quality compared to the 3D template-based approaches. % Rather, they aim less challenging scenes in more general settings, which is opposite to the direction of our scenarios. 
%
%%In practice, more views are required to obtain accurate 3D reconstructions. All of the previous work use a few cameras, and they use pre-trained 3D priors such as bone length, joint angles, or body color. None of the previous work has been applied on challenging social scenes as the ones presented in this paper.
%
%%Our method also lies in this direction, and demonstrate that fusing the pose detector in large number of views shows the state-of-the-art performance in challenging social motion capture scenarios with great generality.  %The biggest difference from previous work is that our method also utilize dense patch trajectory stream to fully exploit temporal coherent.
%
%%\subsection{Positioning of our work}
%%With a few exceptions, much of this work has considered individual activity and where multiple people interact they: (1) perform large visually distinctive motions (in contrast to subtle social behavior), (2) do not exceed three participants; and (3) remain well-separated to make easy to find correspondence between visual cues such as silhouette and mesh model. In this paper, the system we present was designed to address these three issues without requiring the participants to be instrumented or scanned in any way.

\pagebreak