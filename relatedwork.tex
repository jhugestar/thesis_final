% !TEX root = thesis.tex

\chapter{Related Work}

This chapter reviews related work in capturing and modeling kinesic signals in social interactions. While nonverbal communication in general includes all types of ``other-than-words" communication channels including Proxemics, Kinesics, Vocalics, and Haptics, in this thesis we use this term to refer to the communication by kinesic signals. 

\section{Early Work In Understanding Social Interaction}

Due to its important role in communication, nonverbal communication has received a lot of attentions by researchers. Historically, Mehrabian found in his research that more than 93 percent of emotional meaning is transmitted nonverbally~\cite{Mehrabian67,Mehrabian81}. Birdwhistell~\cite{Birdwhistell70} further asserted that nonverbal communication accounts for approximately two-thirds of what we communicate. Although there exist controversy regarding the quantification of the relative importance of nonverbal signals, it is still widely accepted by researchers that nonverbal signals have more impact than the verbal part in communications~\cite{Moore13}.

Nonverbal communication are often categorized into subfields. Hall first introduced the concept of proxemics to describe how humans use their personal space during communication~\cite{Hall66}, and similarly Kendon studied spatial and orientational formations (named F-formation) established when multiple people communicate in a common space~\cite{kendon90}. Birdwhistell presented the term ``kinesics" to refer to the study of face and body movements of human in communication~\cite{Birdwhistell52, ekman1969}. Among them, facial expressions have been gained most of the attentions by researchers. Ekman pioneered the study of relation between emotions and facial expressions, and best known for the Facial Action Code System (FACS), a system to describe facial expressions using combinations of atomic units (Action Units)~\cite{ekman1977facial}. Since then, this system remains a standard to annotate and measure facial expressions, making a broad impact in various fields. Body gestures is relatively poorly explored area compared to the face, although multiple researchers address the importance of body languages in communications~\cite{Gelder09, Moore13, Meeren-2005, Aviezer-2012}. Surprisingly study for nonverbal communication is still in its infancy, and the approaches proposed several decades ago are still the most widely used methods available~\cite{Moore13}. 

Cameras have been used as a tool to record and study social interaction. Even Darwin, in his foundational treatise on the expression of emotion, used photographs to prompt participant response to expressions~\cite{Darwin-1872}. Since then, photographs have been--and continue to be--a fundamental tool in studying social behavior~\cite{Hall-1962,Izard-1971,Ekman-1977}. When the video camera was invented, it too became an integral tool to study the dynamics of social interaction~\cite{Muybridge-1887,Yarbus-1967}. In most of the work, however, the rerecorded scenes are analyzed by human annotators requiring them to spend an enormous amount of time. More importantly, the observer-based annotation system is subject to bias despite efforts to make annotation guidelines, and subtle details in nonverbal signals are ignored due to the limitation in representing them by manual annotations. 

\section{Automatically Measuring 3D Kinesic Signals}

In computer vision, there have been a large number of approaches to measure 3D structure and motion of dynamically moving people using multiple camera sensors. Kanade et al.~\cite{Kanade-1997} pioneered the use of multi-view sensing systems to ``virtualize" reality, using 51 cameras mounted on a geodesic dome of 5 meters in diameter. A number of systems were subsequently proposed to produce realtime virtualizations~\cite{Matusik-2000,Matsuyama-2002,Gross-2003,Petit-2009}. Vlasic et al.~\cite{Vlasic-2009} recovered detail by applying multi-view photometric stereo constraints using a system with 1200 lights on a dome and eight cameras. More recently, a multimodal multi-view stereo system fusing 53 RGB cameras and 53 infrared cameras has been proposed to reconstruct high quality 3D virtual characters~\cite{Collet-15}. 

Methods explicitly tackle markerless motion capture by producing 3D skeletal structures over time similar to their marker-based counterparts~\cite{Gall-09, Gavrila-96, Cheung-05,Plankers-03, Bregler-04, Kehl-06, Corazza-10, Vlasic-08, Brox-10, Stoll-11, deAguiar-2008, Vlasic-2008, Furukawa-2008}. The methods deform pre-defined articulated templates of fixed topology to recover the details that were subsampled or occluded in the set of views at a time instant. These methods require an offline method to generate a rigged 3D model for each individual, and the quality of the template is important to achieve high accuracy. The template models need to be aligned at the initial frame to be tracked, and usually a predefined pose (such as a T-pose) are assumed and performed by all individuals. The methods in this area fundamentally suffer from topological changes restricted by the template model, and, similar to other tracking methods, error accumulation is a critical issue in tracking for long durations. Although the 3D template-based method shows good performance---and has become a standard in markerless motion capture approaches---the requirement of a high quality 3D template for each individual limits the practicality of the method, especially in our scenario where dozens of individuals are involved, as the method does not scale well to multiple people. Previous work is demonstrated on a single actor with few exceptions \cite{Ye-2012, Liu-2013}. For example, it is required to segment image cues per subject to track them independently as in~\cite{Liu-2013}, which becomes more complicated if a large number of people are involved, as in our scenes. It should be noted that none of the previous markerless motion capture approaches focus on capturing non-verbal social behaviors of multiple naturally interacting people.


\section{Computationally Modeling Kinesic Signals}
Over the last decade, there has been increasing interests in computationally analyzing nonverbal communication by measuring signals via computer vision techniques.  Analyzing facial expression is one of the core examples~\cite{ChuDC13, Torre15, shan2009facial}. Other literatures present methods to automatically detect social cues from photos and videos, including detecting F-formation~\cite{setti2015f}, recognizing proxemics~\cite{yang2012recognizing}, recognizing emotions by body pose\cite{schindler2008recognizing}, and detecting social saliency~\cite{park20123d}. Affective Computing has also been growing up rapidly, where video cameras and other sensor measurements (EMG, electrodermal skin response, and heat rate) are used with computer vision and machine learning techniques to analyze emotion, social behavior, and roles~\cite{picard1997affective} in social interaction. 

%Dataset
The availability of large scale data is essential in computational analysis of social interaction. The AMI Meeting Corpus is one of the most extensive database containing group interactions, but only contains a contrived table meeting scenarios with limited number of views~\cite{carletta2005ami}. Several other datasets recording unstructured social scenes have also been presented, where multiple people (from 5 to 14 subjects) naturally communicate without restrictions in their behavior~\cite{Zen-10,Cristani-11,SALSA-15}. In contrast to the scenes captured in structured environment such as round-table meetings~\cite{carletta2005ami, Lepri-12}, the subjects in such unstructured environments show richer social signals in their body motion, locations, and orientations. However, due to the unconstrained nature, it is challenging to measure body motion of subjects, and, thus, relatively low dimensional signals (e.g., quantized body/head orientation) often are considered. None of the previous work addresses to reconstruct full body skeletal motion of individuals in social situations. %such challenging scenarios, although rich social signals are embedded in those subtle motions. 
%
%\section{Human Motion Prediction}
%Predicting future human motion is an emerging area in computer vision and machine learning. Researchers propose approaches of predicting pedestrian's future trajectory~\cite{kitani2012activity}, forecasting human interaction in dyadic situations~\cite{huang2014action}. More recently, Deep Neural Network are used to predict future 3D motion from motion capture data~\cite{mnih2012conditional, Fragkiadaki_2015_ICCV, jain2016structural}, but they only focus on single subject's motion. A few literatures address point motion trajectory prediction in social situations~\cite{helbing1995social, alahi2016social}.

%
%\section{Human Pose Detection in 2D Images}
%%\subsection{Single View Pose Detection and Application in Multi-View}
%
%Over the last few years, single view 2D pose estimation method shows great advances based on Convolutional Neural Network framework with large scale human pose datasets~\cite{Tompson-14,Wei-2016}. The state-of-the-art method~\cite{Wei-2016} shows an excellent performance in various environments with varying subject's shape, appearance, and scales. Recently, a few methods facilitate body pose detectors in multiple views to reconstruct 3D body poses~\cite{Burenius2013, Amin-13, Belagiannis2014, Elhayek-15, Elhayek-16}. To infer 3D skeletal parameters from 2D pose detection cues, unary and pairwise terms are defined based on the pre-training data of joint length, relative joint angles, and body colors. The methods are performed at each time independently in fewer camera setting, and thus they typically suffer from motion jitter. Although the results show potential in general environment settings (e.g., outdoors), the methods in this category do not yet reach similar quality compared to the 3D template-based approaches. % Rather, they aim less challenging scenes in more general settings, which is opposite to the direction of our scenarios. 
%





%Depth sensors such as the Kinect~\cite{Shotton2011,Baak2011} are also emerging as a promising sensing modality. The main advantage of this sensor is that it can produce 3D pose from a single view. However, this approach to body pose recognition directly interferes with social interaction: the Kinect requires people to stand facing towards the sensor to get reasonable results. Using multiple Kinects has potential~\cite{Ye-2012} in that it may produce dense point cloud easily, but how to fuse them for 3D pose estimation has not been explored thoroughly. %, and more importantly, synchronization among Kinects is inherently challenging in the current system specification. 



%
%%In practice, more views are required to obtain accurate 3D reconstructions. All of the previous work use a few cameras, and they use pre-trained 3D priors such as bone length, joint

%
%How to collect and measure nonverbal signal data is important to pursue a data-driven approach for the goal. However, only few dataset contains socially interacting groups with limited measurements ~\cite{alameda2016salsa, mccowan2005ami, lepri2012connecting}. The scene of the sequences are often a table setup limiting free body movement and capturing upper body only, or limited resolution from distances focusing only people's body locations and coarse orientations. Other datasets provide rich 3D body motion information by motion capture techniques but only for single subjects\cite{gross2001cmu, h36m_pami, sigal2010humaneva}. More recently, full body motion capture data of interacting groups using a large number of camera system is proposed for social interaction captures~\cite{Joo-15}. This work shows great potential in collecting a large scale social interaction data without priming in contrast to motion capture techniques. 
%




%On the other hand, marker-less motion capture has been extensively studied for last decade in computer vision area~\cite{Gall-09, Gavrila-96, Cheung-05,Plankers-03, Bregler-04, Kehl-06, Corazza-10, Vlasic-08, Brox-10, Stoll-11}. The researches aim to achieve similar performance to their marker-based counterparts to overcome the limitation of attaching markers on the target subjects. Although the marker-less nature is also the core in capturing social signaling addressed in this paper, in contrast to the focus of psychology community, previous work in this domain mainly focus on capturing motion of single individuals with few exceptions~\cite{Elhayek-15, Liu-2013}, and, more importantly, the methods have never been applied to capture the non-verbal cues of communicating multiple people. In previous methods, smaller number of cameras (less than 15) are used and strong model priors which usually represented as 3D model templates (articulated skeletons with shape/color priors) are used to overcome the ambiguities caused by the limited views. It is obvious that the problem becomes much more challenging, if multiple subjects are captured by such small number of views, and stronger priors about the scene are needed (e.g., a rigged 3D model generated by laser scanning for accurate 2D segmentation as in~\cite{Liu-2013}. However, relying on the strong model prior is not suitable in our scenario where tens of subjects should be participated for social study and, more importantly, any potential bias affecting their naturalism should be avoided. In ideal, the method need to capture the scene with minimum interference without requiring any laborious model building step and without instructing them to perform a pre-defined posture to align or initialize the model during the capture (e.g., imagine how hard it is if we capture the interaction between a toddler and his/her mom as in one of our example). It should be also noted that the people's motion usually seen during the social interactions are distinctive from the scenes (e.g., jumping, dancing, and acrobatic motions) usually demonstrated in the previous work. For example, the frequently occurred poses in our dataset as shown in Figure~\ref{fig:iconicPoses} have lots of topological changes and severe self occlusions where the template model based tracking method mainly suffer from. That is, more challenging problems, capturing motions of multiple people without limiting their motion, should be addressed with minimum interference (no 3D template model building stage and no requirement of performing canonical posture for initialization). 
%While the major stream of previous work aim the direction to use smaller number of cameras or even single view depth camera for single individual's less socially informative motion, our approach pursues the other direction which has not been explored yet: capturing social signals of interacting multiple people with least constraint to them (ideally prior free), but instead using unlimited system power. 





%\section{Measuring Nonverbal Signals}
%\begin{itemize}
%	\item Psychology and Sociology
%		\subitem Temperature
%		\subitem Electronic signal (skin or brain)
%		\subitem electrocardiogram, electromyogram, skin conductivity,respiration [Healey and Picard 2004]
%		\subitem Eye tracking
%		\subitem Face detector
%	\item Machine Learning, Affective computing, Multi modality, Virtual agent
%		\subitem Face detector 
%		\subitem Body detector
%		\subitem Manual orientation
%	\item Computer vision and Graphics
%		\subitem Multiview system
%		\subitem Markerless motion capture (multi subjects)
%		\subitem Face capture
%	\item Our contribution
%		\subitem multiple people
%		\subitem any orientation
%		\subitem minimum restriction
%		\subitem subtle details
%\end{itemize}
%
%\section{Predicting Nonverbal Signals}
%\begin{itemize}
%	\item Psychology and Sociology
%			\subitem ???
%	\item Machine Learning, Affective computing, Multi modality, Virtual agent
%			\subitem F-formation detection
%			\subitem Leader detection. sentiment analysis, happinesss...
%	\item Computer vision and Graphics
%			\subitem Hyun soo's 
%			\subitem Activity forecasting
%			\subitem Katarighna, Structured RNN, Feng's 
%	
%\end{itemize}
%

%
%\section{Automated Group Behavior Analysis}
%Over the last decade, there has been increasing interest in automatically analyzing multiple people's social interaction using multiple camera sensors. Several datasets recording unstructured social scenes are presented, where multiple people (from 5 to 14 subjects) naturally communicate without restriction in their behavior~\cite{Zen-10,Cristani-11,SALSA-15}. In contrast to the scenes captured in structured environment such as round-table meetings~\cite{Lepri-12}, the subjects in such unstructured environments show richer social signals in their body motion, locations, and orientations. However, due to the unconstrained nature, it is challenging to measure their body motion because of severe occlusions among people. Thus, the previous work in this area usually aims to get coarse level of measurement (e.g., quantized body/head orientation), and they rather focus on higher level social understanding from the coarse measurements, such as F-formation detection~\cite{Lepri-12} and personality predictions~\cite{SALSA-15,Zen-10}. None of the previous work in this domain addresses to reconstruct full body skeletal motion of individuals in such challenging scenarios, although rich social signals are embedded in those subtle motions. 
%
%%On the other hand, marker-less motion capture has been extensively studied for last decade in computer vision area~\cite{Gall-09, Gavrila-96, Cheung-05,Plankers-03, Bregler-04, Kehl-06, Corazza-10, Vlasic-08, Brox-10, Stoll-11}. The researches aim to achieve similar performance to their marker-based counterparts to overcome the limitation of attaching markers on the target subjects. Although the marker-less nature is also the core in capturing social signaling addressed in this paper, in contrast to the focus of psychology community, previous work in this domain mainly focus on capturing motion of single individuals with few exceptions~\cite{Elhayek-15, Liu-2013}, and, more importantly, the methods have never been applied to capture the non-verbal cues of communicating multiple people. In previous methods, smaller number of cameras (less than 15) are used and strong model priors which usually represented as 3D model templates (articulated skeletons with shape/color priors) are used to overcome the ambiguities caused by the limited views. It is obvious that the problem becomes much more challenging, if multiple subjects are captured by such small number of views, and stronger priors about the scene are needed (e.g., a rigged 3D model generated by laser scanning for accurate 2D segmentation as in~\cite{Liu-2013}. However, relying on the strong model prior is not suitable in our scenario where tens of subjects should be participated for social study and, more importantly, any potential bias affecting their naturalism should be avoided. In ideal, the method need to capture the scene with minimum interference without requiring any laborious model building step and without instructing them to perform a pre-defined posture to align or initialize the model during the capture (e.g., imagine how hard it is if we capture the interaction between a toddler and his/her mom as in one of our example). It should be also noted that the people's motion usually seen during the social interactions are distinctive from the scenes (e.g., jumping, dancing, and acrobatic motions) usually demonstrated in the previous work. For example, the frequently occurred poses in our dataset as shown in Figure~\ref{fig:iconicPoses} have lots of topological changes and severe self occlusions where the template model based tracking method mainly suffer from. That is, more challenging problems, capturing motions of multiple people without limiting their motion, should be addressed with minimum interference (no 3D template model building stage and no requirement of performing canonical posture for initialization). 
%%While the major stream of previous work aim the direction to use smaller number of cameras or even single view depth camera for single individual's less socially informative motion, our approach pursues the other direction which has not been explored yet: capturing social signals of interacting multiple people with least constraint to them (ideally prior free), but instead using unlimited system power. 
%
%
%\section{Markerless Motion Capturing Using Multiple View Systems}
%%To avoid potential interference on the social signaling, it is essential to measure the scene non-intrusively, for example without using explicit retro-reflective marker with black tight suit or attaching inertial sensors on the subject's body. 
%
%%Besides RGB cameras, motion capture methods provide precise dynamics measurements and have also been used to study social behavior~\cite{McDonnell-2008}, despite the interference caused by markers on social signaling. 
%
%In computer vision, there has been a large number of approaches to measure 3D structure and motion of dynamically moving people using multiple camera sensors. Kanade et al.~\cite{Kanade-1997} pioneered the use of multi-view sensing systems to ``virtualize" reality, using 51 cameras mounted on a geodesic dome of 5 meters in diameter. A number of systems were subsequently proposed to produce realtime virtualizations~\cite{Matusik-2000,Matsuyama-2002,Gross-2003,Petit-2009}. Vlasic et al.~\cite{Vlasic-2009} recovered detail by applying multi-view photometric stereo constraints using a system with 1200 lights on a dome and eight cameras. More recently, a multimodal multi-view stereo system fusing 53 RGB cameras and 53 infrared cameras has been proposed to reconstruct high quality 3D virtual characters~\cite{Collet-15}. 
%
%Other methods explicitly tackle the markerless motion capture by producing 3D skeletal structures over time similar to the marker-based counterparts~\cite{Gall-09, Gavrila-96, Cheung-05,Plankers-03, Bregler-04, Kehl-06, Corazza-10, Vlasic-08, Brox-10, Stoll-11, deAguiar-2008, Vlasic-2008, Furukawa-2008}. The methods deform pre-defined articulated templates of fixed topology to recover the details that were subsampled or occluded in the set of views at a time instant. These methods require an offline method to generate a rigged 3D model for each individual, and the quality of the template is important to achieve high accuracy. The template models need to be aligned at the initial frame to be tracked, and usually a predefined pose (such as a T-pose) are assumed and performed by all individuals. The methods in this area fundamentally suffer from topological changes restricted by the template model, and, similar to other tracking methods, error accumulation is a critical issue in tracking for long durations. Although the 3D template-based method shows good performance---and has become a standard in markerless motion capture approaches---the requirement of a high quality 3D template for each individual limits the practicality of the method, especially in our scenario where dozens of individuals are involved, as the method does not scale well to multiple people. Previous work is demonstrated on a single actor with few exceptions \cite{Ye-2012, Liu-2013}. For example, it is required to segment image cues per subject to track them independently as in~\cite{Liu-2013}, which becomes more complicated if a large number of people are involved, as in our scenes. It should be noted that none of the previous markerless motion capture approaches focus on capturing non-verbal social behaviors of naturally interacting multiple people.
%
%%In contrast, our method is designed to be free from the above limitations. Our method does not rely on the predefined 3D template but based on the detection and motion cue to reconstruct the people's motion without prior assumptions about the scene and individuals: the scene may have arbitrary number of people; people can be of any shape and appearance (children to adults, small to tall, and arbitrary clothing);  No template calibration or alignment is needed allowing people to leave or participate during the interaction; motion is not restricted and free from topological constraints. Neither background subtraction nor a segmentation is required. %Our dataset contains multiple people's natural interactions (up to 8), and people performs any challenging natural motion without constrains (crossing arms, chin on a hand, and so on). 
%
%%, and reconstruct the 3D body motion of arbitrary number of people directly from multiple views. Our method well fits to the goal of social study where large number of subjects are studied (to avoid the need of making many predefined model) and subject are present and leave freely (to avoid the need of model alignment).
%
%%A number of approaches presented techniques to optimize free-viewpoint exploration of dynamic scenes  ~\cite{Carranza-2003,Zitnick-2004,Nobuhara-2004,Matusik-2004,Wilburn-2005,Vedula-2005}. These techniques used a variety of proxies of varying accuracy and used as few as eight \cite{Zitnick-2004} and as many as 128 \cite{Wilburn-2005}. 
%%As another direction, multi-camera array systems have been proposed to create virtual sensors to capture light fields of the scene [Levoy, Zitnik] for various application in computational photography (high resolution and High-Dynamic Range, Synthetic Aperture) and graphics (space-time interpolation).  
%%http://old.siggraph.org/publications/2006cn/course07.pdf
%
%\subsection{Pose Detection Based Approach}
%%\subsection{Single View Pose Detection and Application in Multi-View}
%
%%Depth sensors such as the Kinect~\cite{Shotton2011,Baak2011} are also emerging as a promising sensing modality. The main advantage of this sensor is that it can produce 3D pose from a single view. However, this approach to body pose recognition directly interferes with social interaction: the Kinect requires people to stand facing towards the sensor to get reasonable results. Using multiple Kinects has potential~\cite{Ye-2012} in that it may produce dense point cloud easily, but how to fuse them for 3D pose estimation has not been explored thoroughly. %, and more importantly, synchronization among Kinects is inherently challenging in the current system specification. 
%
%Over the last few years, single view 2D pose estimation method shows great advances based on Convolutional Neural Network framework with large scale human pose datasets~\cite{Tompson-14,Wei-2016}. The state-of-the-art method~\cite{Wei-2016} shows an excellent performance in various environments with varying subject's shape, appearance, and scales. Recently, a few methods facilitate body pose detectors in multiple views to reconstruct 3D body poses~\cite{Burenius2013, Amin-13, Belagiannis2014, Elhayek-15, Elhayek-16}. To infer 3D skeletal parameters from 2D pose detection cues, unary and pairwise terms are defined based on the pre-training data of joint length, relative joint angles, and body colors. The methods are performed at each time independently in fewer camera setting, and thus they typically suffer from motion jitter. Although the results show potential in general environment settings (e.g., outdoors), the methods in this category do not yet reach similar quality compared to the 3D template-based approaches. % Rather, they aim less challenging scenes in more general settings, which is opposite to the direction of our scenarios. 
%
%%In practice, more views are required to obtain accurate 3D reconstructions. All of the previous work use a few cameras, and they use pre-trained 3D priors such as bone length, joint angles, or body color. None of the previous work has been applied on challenging social scenes as the ones presented in this paper.
%
%%Our method also lies in this direction, and demonstrate that fusing the pose detector in large number of views shows the state-of-the-art performance in challenging social motion capture scenarios with great generality.  %The biggest difference from previous work is that our method also utilize dense patch trajectory stream to fully exploit temporal coherent.
%
%%\subsection{Positioning of our work}
%%With a few exceptions, much of this work has considered individual activity and where multiple people interact they: (1) perform large visually distinctive motions (in contrast to subtle social behavior), (2) do not exceed three participants; and (3) remain well-separated to make easy to find correspondence between visual cues such as silhouette and mesh model. In this paper, the system we present was designed to address these three issues without requiring the participants to be instrumented or scanned in any way.

\pagebreak