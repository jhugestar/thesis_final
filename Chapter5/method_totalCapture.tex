% !TEX encoding = UTF-8 Unicode
% !TEX root = thesis.tex

\chapter{Measuring Total Body Motion Capture}
\label{chapter:totalcapture}



\section{Introduction}
Social communication is a key function of human motion \cite{Birdwhistell70}. We communicate tremendous amounts of information with the subtlest movements. Between a group of interacting individuals, gestures such as a gentle shrug of the shoulders, a quick turn of the head, or an uneasy shifting of weight from foot to foot, all transmit critical information about the attention, emotion, and intention to observers. Notably, these social signals are usually transmitted by the organized motion of the whole body: with facial expressions, hand gestures, and body posture. These rich signals layer upon goal-directed activity in constructing the behavior of humans, and are therefore crucial for the machine perception of human activity. 

However, there are no existing systems that can track, without markers, the human body, face, and hands simultaneously. Current markerless motion capture systems focus at a particular scale or on a particular part. Each area has its own preferred capture configuration: (1) torso and limb motions are captured in a sufficiently large working volume where people can freely move~\cite{deAguiar-2008, Gall-09, Stoll-11, Elhayek-15}; (2) facial motion is captured at close range, mostly frontal, and assuming little global head motion~\cite{Beeler:SIGGRAPH2010,ghosh2011multiview, Beeler:SIGGRAPH2011, bradley2010high, valgaerts2012lightweight}; (3) finger motion is also captured at very close distances from hands, where the hand regions are dominant in the sensor measurements~\cite{Oikonomidis-12, Tompson-14a, Sridha-15, Tzionas-16}. These configurations make it difficult to concurrently analyze the full spectrum of social signalling.

% % The following paragraph has nicer sentences than above:

%In this paper, we present an approach to capture the motion of the principal body parts for multiple interacting people (see Fig.~\ref{fig:teaser2}). The fundamental difficulty of such capture is caused by the scale differences of each part. For example, the torso and limbs are relatively large and necessitate coverage over a sufficiently large working volume, while fingers and faces, due to their smaller feature size, require close distance capture with high resolution and frontal imaging. With off-the-shelf cameras, the resolution for face and hand parts will be limited in a room-scale, multi-person capture setup. 

To overcome this sensing challenge, we present a novel generative body deformation model that has the ability to express the motion of each principal body part. In particular, we describe a procedure to build an initial body model, named ``Frank", by seamlessly consolidating available part template models~\cite{Loper2015,cao2014facewarehouse} into a single skeleton hierarchy. To fit this model to data, we leverage keypoint detection (e.g., faces~\cite{Torre15}, bodies~\cite{Wei2016,cao2016realtime,Newell-16}, and hands~\cite{simon2017hand}) in multiple views to obtain 3D keypoints which are robust to multiple people and object interactions. We fit the ``Frank'' model to a capture of 70 people, and learn a new deformation model, named ``Adam", capable of additionally capturing variations of hair and clothing with a simplified parameterization. We present a method to capture the total body motion of multiple people with the 3D deformable model. Finally, we demonstrate the performance of our method on various sequences of social behavior and person-object interactions, where the combination of face, limb, and finger motion emerges naturally.

\section{Related Work}

Marker-based motion capture systems that track retro-reflective markers~\cite{VICON, woltring1973new} are the most widely used method to capture human body motion. However, in addition to a laborious process of attaching markers on subjects, these methods still suffer from major limitations including: (1) a necessity of sparsity in marker density for reliable tracking, which limits the spatial resolution of motion measurements~\cite{park2006capturing}; (2) a limitation in automatically handling occluded markers which requires expensive manual clean-up; and (3) markers on the faces, bodies, and hands hinder participants from engaging in natural social interaction. Due to these limitations, capturing the total body motion of interacting people is still a challenging problem even in state-of-the-art motion capture systems~\cite{VICON}. 

Markerless motion capture methods have been explored over the past two decades to achieve the same goal of motion capture systems, but they tend to implicitly admit that their performance is inferior to their marker-based counterpart, advocating their ``markerless'' nature as the major advantage. Most markerless motion capture methods largely focus on the motion of the torso and limbs. The standard pipeline is based on a multiview camera setup and tracking with a 3D template model~\cite{Liu-2013, Gavrila-96, Cheung-05, Bregler-04, Kehl-06, Corazza-10, Vlasic-08, Brox-10, Stoll-11, deAguiar-2008, Elhayek-15}. In this approach, motion capture is performed by aligning a 3D template model to the measurements, which can include colors, textures, silhouettes, point clouds, and keypoints. Recent methods exploit a generative deformable body model~\cite{anguelov2005scape, Loper2015, pons2015dyna} to express both shape and body variations of humans. Since these body models often assume minimum clothing for subjects, explicit modeling for clothing is needed to capture clothed subjects~\cite{zhang2017detailed, pons2017clothcap}. Recent advances in 2D keypoint detection~\cite{ Newell-16, cao2016realtime, Wei2016} make it possible to reliably reconstruct 3D keypoints in a multiview setup, where a 3D model can be fitted~\cite{Elhayek-15, Joo-15, joo2017panoptic}. A specific strength of learning-based detectors is that they can provide a ``guess"  for occluded parts, based on the spatial human body configurations learned from a large-scale 2D pose dataset. Note that we differentiate markerless motion capture approaches, producing motion parameters as output, from multiview performance capture approaches~\cite{Vlasic-2009, Furukawa-2008} which aim to obtain detailed surface shapes by free-form mesh deformations. With the introduction of commodity depth sensors, single-view depth-based body motion capture also became a popular direction~\cite{Baak-13, Shotton2011}. More recently, a collection of approaches aims to reconstruct 3D skeletons directly from monocular images, either by fitting 2D keypoint detections with a prior on human pose~\cite{Zhou2015,Bogo2016} or getting even closer to direct regression methods~\cite{Zhou2016,Mehta2017,tome2017lifting}.

In all earlier work, face and hand motion captures are often considered as separate research domains.  Facial scanning and performance capture has been greatly advanced over the last decade. There exist multiview methods showing excellent performance on high-quality facial scanning~\cite{Beeler:SIGGRAPH2010,ghosh2011multiview} and facial motion capture~\cite{Beeler:SIGGRAPH2011, bradley2010high, valgaerts2012lightweight}. Recently, lightweight systems based on a single camera show compelling performance by leveraging a morphable 3D face model on 2D measurements~\cite{garrido-tog-2013, Torre15, li2013realtime, thies2016face2face, cao2014facewarehouse, cao2015real, wu2016anatomically}. Most of these methods are based on a deformable 3D face rig such as the method of Cao et al. \cite{cao2014facewarehouse}. Hand motion capture is mostly led by single depth-sensor based methods~\cite{Oikonomidis-12, Tang-14, Tompson-14a, Keskin-12,Xu-13,Sun-15,Wan-16, Sridhar-13, Sharp-15, Sridha-15, Tzionas-16, Ye-16}, with few exceptions based on multi-view systems~\cite{Ballan-12, Sridhar-13, MANO:SIGGRAPHASIA:2017}. Recently, 2D hand keypoint detection and the use of it to obtain 3D hand keypoints in a multiview setup are introduced by Simon et al.~\cite{simon2017hand}. Notably, a generative 3D model that can express body and hands was also introduced by Romero et al.~\cite{MANO:SIGGRAPHASIA:2017}. 

In contrast, this paper presents the first approach for ``total'' markerless motion capture of multiple interacting people, producing a parameterized representation that jointly captures the time-varying body pose, hand pose, and facial expressions of each of the interacting participants. %To accomplish this, we use a calibrated multiview camera system and unify existing part models for the body, hands, and face into a single skeleton hierarchy and model that we call ``Adam'', which can more easily be fit to people engaging in natural social interactions.

\input{Chapter5/tbc_modelbuilding}
\input{Chapter5/tbc_tracking}
\input{Chapter5/tbc_totalmodel}
\input{Chapter5/tbc_result}

% Here, discuss what the advantages are of Adam over Frank.

\section{Discussion}
We present the first markerless method to capture total body motion including facial expression, body motion from torso and limbs, and hand gestures at a distance. To achieve this result, we present two types of models, Frank and Adam, which can express motion in each of the parts. Our reconstruction results show compelling and realistic results, even when using only sparse 3D keypoint detections to drive the models.  As a current limitation of our system, Adam lacks expressive power in surface details due to the limited number of subjects in training. However, the major value of Adam model over Frank lies in its simpler representation to capture total body motion, which can be useful for other applications.
%demonstrating that capturing all body parts are important due to their correlations. 

There are two interesting points our paper raises. First, markerless hand motion capture, often considered too challenging compared to body and face captures, shows better localization quality in our results. Body joints are located inside the body and are hard to localize for clothed subjects, and the accuracy of face reconstruction greatly decreases once the face is not facing any camera. However, hands are often bare and the hand keypoint detector~\cite{simon2017hand} provides guessed measurements with high confidence even in self-occlusions, which can be fused in multiple views. Second, our results show a potential that markerless motion capture can eventually outperform its marker-based counterpart. Marker-based methods strongly suffer from occlusions, making it hard to capture both body and hands together, while our method can still exploit measurements for occluded parts by learning-based keypoint detectors.
