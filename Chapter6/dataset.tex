% !TEX root = ../thesis.tex

\chapter{A Large-Scale Social Interaction Corpus}
\label{chapter:dataset}
Availability of a large-scale dataset is essential to computationally investigate the nonverbal communication in a data-driven manner. Despite existing datasets that provide measurements for human motion and behaviors~\cite{carletta2005ami, Lepri-12, Zen-10,Cristani-11, SALSA-15, h36m_pami}, there is no dataset that satisfies the following core requirements for understanding nonverbal human behaviors: (1) capturing 3D full body motion with a broad spectrum of nonverbal cues (including face, body, and hands); (2) capturing signals of naturally interacting groups (more than two people to include attention switching); and (3) collecting the data at scale. The limited availability of the dataset motivates us to build a new dataset that contains social interactions among hundreds of interacting groups with a broad spectrum of 3D body motion measurements. The key properties of our dataset are as follows:
\begin{itemize}
	\item Our dataset contains naturally interacting multiple people in a negotiation game scenario, where the game is carefully designed to induce natural and spontaneous interaction
	\item Participants   are randomly recruited
	\item No behavioral restriction is instructed to participants during the capture
	\item A broad spectrum of social signals, including the motion from faces, bodies, and hands, are measured using our markerless motion capture (Chapters~\ref{chapter:mocap} and \ref{chapter:totalcapture})
		\item Our dataset contains synchronized multiple modalities, including RGB videos from over 500 views, depth maps from 10 RGB+D sensors, and sound from 23 microphones  
		\item Voice signals of individuals are recorded via wireless and wired microphones, and speaking status and timing of each subject are manually annotated
		\item 3D point clouds are provided by fusing the depth maps from 10 RGB+D sensors
	\end{itemize}
	
	Our dataset provides a new opportunity to investigate the dynamics of various interpersonal nonverbal behavioral cues emerging in social situations. Our dataset is captured under a university-approved IRB protocol\footnote{IRBSTUDY2015\_00000478} and publicly released for research purposes, with agreements from all participants\footnote{\url{http://domedb.perception.cs.cmu.edu}}. 
%\begin{figure}
%	\centering
%	\includegraphics[width=\linewidth]{ssp_fig/haggling_ex}
%	\caption{An example of the haggling sequence. (Left) an example scene showing two sellers and one buyer. (Right) Reconstructed 3D social signals showing body, face, and 3D hand motion.} 
%	\label{fig:haggling_example}
%\end{figure}


\section{Related Work}
Recognizing emotions from social signals is one of the most popular directions as a way to analyze nonverbal behaviors. Most prior approaches in this domain focus on deciphering the semantic meanings of social signals, which are often annotated into a few discrete categories~\cite{ekman1969} or a set of latent dimensions\cite{osgood1952nature, russell1979affective, plutchik2001nature} (see a recent survey~\cite{noroozi2018survey}). A lot of datasets have been presented to tackle this problem~\cite{lucey2010extended,gross2010multi,dhall2013emotion, mollahosseini2016facial, fabian2016emotionet, mollahosseini2017affectnet}. Recognizing emotions from body gestures is a less investigated field. Almost all databases in this domain are collected from actors where the actors are instructed to behave certain emotions~\cite{gunes2006bimodal, banziger2012introducing, de2004modeling}. Several approaches demonstrate that not just facial expression but the context of the scene including body gestures is important in emotion perception~\cite{barrett2011context, aviezer2008angry}. The dataset collected for this direction contains a single subject only, and thus they are not applicable for modeling nonverbal communication.
%More ICMI DB. Recognizing X

A few datasets contain the scenes of socially interacting groups~\cite{mccowan2005ami, zancanaro2006automatic, lepri2012connecting, rehg2013decoding}. The interactions in these datasets are often in a table setup, where participants’ motions are limited and only upper-body of the participants are captured. Importantly, these datasets do no provide accurate 3D motion capture measurements. There are datasets that capture free-standing conversational groups (e.g., cocktail party)~\cite{Zen-10, Cristani-11, SALSA-15, farenzena2009social}, but these databases also contain coarse signal annotations only such as location and orientations of torso, targeting to study social formation or category-level recognition tasks (e.g., speaker, personality, or role recognition).
%More ICMI DB

Datasets providing accurate 3D body motion capture exist in computer vision and graphics~\cite{gross2001cmu, h36m_pami, sigal2010humaneva}.  However, they often contain single subjects and do not include communicative behaviors. The motion capture data capturing casual social communication is extremely rare. 
%Vision/Grapihics/ Human motion

%
%Notably, there is not previous work where socially interacting groups are non-intrusively captured with full body motion capture measurements. 

%\subsection{Social Signal Processing DB:}

%Emilya: Emotional body database
%FABO corpos
%GEMEP corpus: actor behave
%Modeling human affective postures: an information theoretic characterization of posture features
%\subsection{Affective Posture Database:}
%A research domain considers to recognize emotions in body gestures. Almost all databases in this domain are collected from actors where actors are instructed to behave certain emotions~\cite{gunes2006bimodal, banziger2012introducing, de2004modeling}. 

%\subsection{Face-to-face Social Interacton Database:}
%SALSA: alameda2016salsa
%AMI meeting db: mccowan2005ami

%Free-standing
%Space speaks: towards socially and personality aware visual surveillance

%Other device:
%13. Pentland, A.: Looking at people: Sensing for ubiquitous and wearable computing.
%IEEE PAMI. 22(1) (2000) 107–119
%14. Choudhury, T., Pentland, A.: The sociometer: A wearable device for understanding
%human networks. In: CSCW - Workshop on ACCUCE. (2002

%\textbf{Social Signal Dataset:}
%How to measure and collect nonverbal signal data is important to pursue a data-driven approach for our goal.  A research domain considers to recognize emotions in body gestures. Almost all databases in this domain are collected from actors where actors are instructed to behave certain emotions without actual social interaction~\cite{gunes2006bimodal, banziger2012introducing, de2004modeling}. Few datasets contain socially interacting group motion~\cite{mccowan2005ami, zancanaro2006automatic, lepri2012connecting, rehg2013decoding}. The scenes in these datasets are often in a table setup, limiting free body movement and capturing the upper-body only. There are datasets that capture free-standing conversational groups (e.g., cocktail party)~\cite{Zen-10, Cristani-11, alameda2016salsa, farenzena2009social}, but these only contain location and orientation measurements for the people, introduced to study the social formation or coarse category level recognition tasks (e.g., speaker, personality, or role recognition).

% Datasets providing rich 3D body motion information captured with motion capture techniques exist, but they contains single subjects' motion only\cite{gross2001cmu, h36m_pami, sigal2010humaneva}. More recently, however, full body motion data of interacting groups using a large number of camera system was proposed for social interaction capture~\cite{Joo-15}. This work shows a potential in collecting a large scale social interaction data without the usual issues caused by wearing a motion capture suit and markers.

%\subsection{Human Motion Capture Database:}
%Datasets providing rich 3D body motion information captured with motion capture techniques exist, but they contains single subjects' non-social motion only\cite{gross2001cmu, h36m_pami, sigal2010humaneva}. 
%
%Notably, there is not previous work where socially interacting groups are non-intrusively captured with full body motion capture measurements. 


\begin{figure}
	\centering
	\includegraphics[trim=0 0 0 0,clip,width=\linewidth]{ssp_fig/haggling_intro}
	\caption{Before starting the social game capture, participants are instructed the game rules and also spent time to be accustomed to the Panoptic Studio environment, as shown in these photos. We follow a common and strict protocol during all captures to avoid any potential bias.} 
	\label{fig:haggling_intro}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[trim=300 0 0 0,clip,width=0.49\linewidth]{ssp_fig/haggling_ex_input}
	\includegraphics[trim=300 0 0 0,clip,width=0.49\linewidth]{ssp_fig/haggling_ex_measure}
	\caption{An example of the haggling sequence. (Left) an example scene showing two sellers and one buyer. (Right) Reconstructed 3D social signals showing the 3D body, 3D face, and 3D hand motion. 3D normal direction from faces and bodies are also computed, and speaking status of each individual, manually annotated, is also visualized here.} 
	\label{fig:haggling_example}
\end{figure}

\begin{table}[h]
	\centering
	
	\begin{tabular}{ l| l | l  }
		\hline	
		Items & Seller 1  &  Seller 2\\
		\hline	
		\hline	
		Phone &  \makecell{Light weight \\ Medium storage}    & \makecell{Medium weight\\ Large storage}\\
		\hline			
		Laptop &  \makecell{Light weight \\ Medium speed}    & \makecell{Medium weight\\ Fast speed}\\
		\hline			
		Tablet PC &  \makecell{Large storage\\ Medium speed}    & \makecell{Medium storage\\ Fast speed}\\
		\hline	
		Speaker &  \makecell{High quality audio\\ Wired}    & \makecell{Medium quality audio\\ Wireless}\\
		\hline	
	\end{tabular}
	\caption{Examples of items assigned to sellers in our Haggling games.}
	\label{table:haggling_items}
\end{table}


\section{The Haggling Game Protocol}
To evoke natural interactions, we involved participants in a social game named the \emph{Haggling} game. We invent this game to simulate a haggling situation among two sellers and a buyer. The triadic interaction is chosen to include interesting social behaviors such as turn taking and attention changes, which are missing in previous dyadic interaction datasets~\cite{rehg2013decoding}. During the game, two sellers are promoting their own comparable products for selling, and a buyer makes a decision about which product he/she buys between the two. The game lasts for a minute, and the seller who has sold his/her product is awarded $\$5$. To maximize the influence of each seller's behavior on the buyer's decision-making, the items assigned to sellers are similar products with slightly different properties. Example items are shown in Table~\ref{table:haggling_items}. 

For every capture, we follow the protocol described below. We randomly recruited participants using CMU Participation Pool\footnote{\url{https://cbdr.cmu.edu/}}. Over the 8 days of captures, 122 subjects participated and 180 haggling sequences were captured (about 3 hours of data). The participants arrived at the lab for the capture first sign on the IRB consent form with an agreement to publicly release the data for research purposes only\footnote. A unique identification number is assigned to each participant, and participants are also equipped with a wireless microphone.  Then, all subjects are informed of the rules of the Haggling game by watching a pre-recorded presentation video together. Notably, they are not instructed about how to behave during the game, nor is their clothing or appearance controlled. All motions in the sequences are spontaneous social behaviors based on the informed game rules. After introducing the game rules, participants are asked to spend time inside the studio so that they can be accustomed to the interior view of the Panoptic Studio. Before starting the capture, groups and roles are randomly assigned, and participants line up based on their orders. We provide descriptions about the items written in small cards to sellers 1 minute before the game, and the sellers return the card before entering the studio. With a starting signal, participants in a group enter the studio and start the haggling game immediately. The positions and orientations of the groups in the system are also spontaneously decided. During the capture, their all social signals including voice, positions, orientations, and body motions are recorded.  We send a signal by ringing a bell 10 seconds before the end of the game, and send the same alarm at the end of the game. After the capture, the buyer annotates the decision between the two items in the prepared result sheet. The captured sequences contain a lot of voluntary social behaviors of diverse people in a common social context. Example scenes are shown in Figure~\ref{fig:haggling_example} and \ref{fig:haggling_db}.
% 
% Example scenes are shown in Figure ~\ref{fig:haggling_example} and \ref{fig:haggling_db}.
%
%In our captures, subjects were informed of the rules of the game but were otherwise not instructed about how to behave, nor was their clothing or appearance controlled. They were also not initially aware of our research goals to avoid potential biases in their gestures. 





%
%\begin{figure}
%	\centering
%	\frame{\includegraphics[width=\textwidth]{ssp_fig/haggling_examples}}
%	\caption{Example scenes of haggling sequences.} 
%	\label{fig:haggling_others}
%\end{figure}



\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{ssp_fig/hagglingdb_ex}
	\caption{Example scenes of haggling sequences with social signal measurements. For each example, HD images overlaid by the projections of 3D anatomical keypoints (from bodies, faces, and hands) are shown, along with a 3D view of the social signal measurements (top right).} 
	\label{fig:haggling_db}
\end{figure}

\section{Measured Social Signals in Our Corpus}
We use our Panoptic Studio System to reconstruct 3D social signals (Chapters~\ref{chapter:system}, \ref{chapter:mocap}, and  \ref{chapter:totalcapture}. As a key advantage, our method does not require attaching markers on the subject's body, and no behavior restrictions nor initialization poses are needed from the subjects. As output, the system captures 3D body motion, 3D face motion, and 3D hand motion for each individual. From these measurements, we additionally compute the body orientation and face orientation by finding the 3D normal directions of torso and face. Finally, we fit our Adam model~\cite{joo2018} to reconstruct both body shape and joint angle parameters, which is the similar form as in a motion capture system. Example visualizations of these social signal measurements are shown in Figure~\ref{fig:haggling_example}, \ref{fig:haggling_measurement_vis}, and \ref{fig:haggling_measurement_adam}. The voice data of each individual is also recorded by wireless microphones assigned to each individual. From the audio signal, we manually annotate a binary speaking label describing whether the target subject is speaking (labeled as $1$) or not speaking (labeled as $0$).
% In summary we measure the following signals for each individual:
%\begin{equation}
%[ \mathbf{x}, \boldsymbol{\theta}, \boldsymbol{\phi}, \mathbf{J}, \mathbf{F}, \mathbf{H}, \mathbf{V}, \mathbf{S} ].
%\label{equation:measurement}
%\end{equation}


\begin{figure}
	\centering
	\includegraphics[width=0.49\textwidth]{ssp_fig/haggling_ex_face}
	\includegraphics[width=0.49\textwidth]{ssp_fig/haggling_ex_facebody}
	\caption{Visualizing part of social signals. (Left) Visualizing only face and speaking annotation where face mesh is reconstructed by the method described in Chapter~\ref{chapter:totalcapture}, (Right) Visualizing face mesh, body skeletons, and speaking annotation excluding social formation. As a benefit of our measurement outputs, we can include (or exclude) specific channels of social signals among all measured signals.} 
	\label{fig:haggling_measurement_vis}
\end{figure}

\begin{figure*}
	\centering
	\includegraphics[width=\textwidth]{ssp_fig/haggling_adam}
	\caption{Example scenes of Haggling sequences with Adam model fitting results. Motions from faces, bodies, and hands are captured in a mesh structure.} 
	\label{fig:haggling_measurement_adam}
\end{figure*}



\section{Panoptic Studio Database}
Our entire dataset contains various types of human motions in diverse scenarios, containing more than 13 hours of sequences. Many researchers and artists in diverse fields including computer science, business, psychology, and visual arts also exploit our system for various applications. We publicly release various such sequences, including several other social games described below. Categories and detailed information on our dataset are shown in the Table~\ref{table:dataset}.

\paragraph{Ultimatum.} Ultimatum is a bargaining game that was first experimentally studied by G\"uth et al.~\cite{Guth-82} and has subsequently become among the most studied games in experimental economics~\cite{Chaudhuri-09}. The game consists of two bargainers who are given a certain amount of money to split ($\$10$ in our experiment). One bargainer, referred to as the proposer, suggests a split of the money, and the other bargainer, referred to as the responder, either accepts the split (and both receive money accordingly) or rejects the split (and neither receive anything). Unlike researchers in experimental economics and game theory, we are interested in evoking interactions rather than predicting outcomes of the game, and we therefore make several adjustments to the usual set up of the game. First, we organized participants into teams of proposers and responders (e.g., two proposers and two responders, or four proposers and one responder). Second, we introduced a one minute, face-to-face discussion phase where the participants discuss what they should do (including both inter- and intra-team discussion). One the discussion phase is over, the proposers suggested a split, which the responders either accept or reject without discussion. Third, we did not control for prior acquaintance. Before each experiment, the subjects were introduced to the game informally, with oral instructions explaining the rules. The proposer(s) entered the eventspace first, followed by the responder(s). 

%
%\subsection{Prisoner's Dilemma} Prisoner's dilemma is a game that is originally framed by Merrill Flood and Melvin Dresher, and formalized by Albert Tucker. Two groups are arrested and they are given a Faustian bargain. Each group may betray the other group. If both group remain silent, both will get less penalty, but if only one group betray the other, the other group will be punished harsh while the betrayers got punished least. Because betraying the other gives them the least penalty, natural conclusion from the matrix enforce them to betray each other even if cooperation is the best scenario for both of them. In our capture, we organized participants into two teams with three people for each, with a moderator who shows the reward matrix and announces a final decision from players. Players are given two minutes for intra-group and inter-group discussions, and make a conclusion by passing a selected card to the moderator between two options. The decisions from both teams are displayed by the moderator at the same time, and participants were compensated according to the decision in the reward matrix.  

\paragraph{Mafia.} Mafia is a game created by Dimitry Davidoff~\cite{Haffner-99} that involves both conflict and cooperation, and produces dynamically changing alliances and rivalries within a group of people. Within the group, two individuals (usually) are secretly assigned the roles of ``Mafia" and the rest are assigned roles or ordinary Villagers. The goal of the Villagers is to determine who among them is Mafia via discussion. It is a turn-based game that involves the Villagers choosing to ``execute" one player every turn---their best consensus guess at who the mafia players are---following by the Mafia secretly choosing to secretly ``execute" a Villager of their choice. The game is notable in that it requires some players to engage in outright deception, and requires other players to try to infer this via the interaction alone. In our capture, we involved eight players in the studio. One of them is determined as an operator, and two Mafias and five Villagers are secretly assigned via selecting a lottery.  During the game, we gave them approximately a minute to discuss before iterating on each turn. A large number of interesting phenomena were observed, including subtle motion and gestures to suspect or deceive the other group. Participants were compensated $\$10$ for their participation.

%\subsection{Haggling.} We invent this game to simulate a haggling situation among two sellers and a buyer. Two sellers are promoting their own comparable products for selling, and a buyer makes the decision which product he/she buys between the two. They are given a minute for the haggling, and the seller who has sold his/her product are awarded $\$5$. To avoid any bias caused by personal preference of buyers about the items, the items provided to sellers are simple descriptions of a same type of product but comparably different properties\footnote{We adjusted the game rule multiple times. In old sequences, sellers are given actual objects for selling}. Our recent captures mainly focus on this game due to its simple social settings, and short durations. To this end, we have invited 122 participants and 180 haggling sequences are captured. 
%
%\subsection{007 Bang.} 007-bang game is a party game originated from Korea. Players are located in a circular form, and a turn is started from a starting person who points at someone in the group by hand saying "0". The pointed person, then, points at someone with saying "0" again, and the next pointed person does the same thing with saying "7" at this time, making "007" in turn. The pointed person by the "7" now points someone with saying "bang", and the left and the right person of the finally shot person by the "bang" raise their hands and shout "ah". This game tries to make people confused, because the finally shot person unconsciously tends to raise his/her hands, or the people next to the finally shot person easily forget their required actions. The people who make mistake get a punishment by getting a back massage from others. The next turn is started from the finally shot person. 



\begin{table}[h]
	\centering
	\begin{tabular}{c| c | c | c }
		\hline	
		Categories & Number of Sequences  & Total Duration  & Num. of people per scene \\
		\hline	
		Haggling & 22  & 232m 10s  & 3   \\
		\hline	
		Range of Motion &  9 & 117m  & 1   \\
		\hline	
		Ultimatum &  6 & 57m 20s & 2-7   \\
		\hline	
		Mafia &  7 &  83m & 3-8   \\
		\hline	
		Dance&  14& 55m 5s & 1-2   \\
		\hline	
		Musical Instruments& 20 & 73m  & 1-3  \\
		\hline	
		Pose& 33 & 120m  & 1  \\ 
		\hline	
		Toddler& 12 & 26m & 1-3  \\ 
		\hline	
		Hands&  7 &  34m & 1-3  \\ 
		\hline	
		Others& 16 & 20m & 3-15 \\
		\hline	
		\hline	
		Total& 176 & 13h 37m 35s & 1-15\\
		\hline	
	\end{tabular}
	\caption{Statistic of Panoptic Studio Dataset}
	\label{table:dataset}
\end{table}

\begin{figure}
	\centering
	\includegraphics[height=0.95\textwidth]{figures/domedb}
	\caption{The Panoptic Studio Dataset website. We have collected a large number of sequences in various situations. All the 521 sensor measurements as well as reconstructed 3D motion capture results are available.} 
	\label{fig:domedb}
\end{figure}

%\section{Expected Contributions in Computer Vision Community}
%While our dataset is mainly intended to study kinesic signals in social situations, there exist a huge potential in using our dataset for various other computer vision topics. Our dataset contains various type of measurement and automatically generated annotations about dynamically moving human motions. Because all the sensor are temporally and spatially calibration, the dataset can be used as a dataset for various type of computer vision problems to learn the relation among video based scene understanding. 
%
%Over last decade, we have seen that a large number of dataset enables to promote high performance in computer vision algorithms. Yet, still it become a major bottleneck in pursueing new direction of research. For example, annotations for the in-the-wild images collected in the internet is largely limited to relatively simple annotations such as scene category, or bounding boxes. Annotations for richer information such as depth, 3D, videos are not only costly, but also unreliable. In such problem, the available dataset is limited to 3D CAD model, synthetic data, and so on. Due to the reason, the most popular items in computer vision community is stationary object such as bed, chairs, tables, and so on. No rich annotation regarding humans are available, although most of the imagery data is about humans. 
%
%Our dataset provide a potential in that direction. 

\pagebreak