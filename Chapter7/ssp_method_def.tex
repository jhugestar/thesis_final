% !TEX root = thesis.tex

\section{Social Signal Prediction}
The objective of \emph{Social Signal Prediction} is to predict the behavior of a target person in a social situation. We hypothesize that target person's behavior is correlated to the behavioral cues of other individuals. For example, the location and orientation of the target person should be strongly affected by the position of conversational partners (known as Proxemics~\cite{Hall66} and F-formation~\cite{kendon90}), and the gaze direction, body gestures, and facial expressions of the target person should also be ``conditioned" by the behaviors of the conversational partners. In the social signal prediction task, we model this conditional distribution among interacting subjects, to ultimately teach a robot how to behave in a similar social situation driven by the behavior of communication partners. There exist cases where the correlation of the social signals among subjects is strong, such as hand-shaking or greeting (waving hands or bowing). But in most of the cases, the correlation is implicit---there exist no specific rules on how to behave given other people's behavior, which makes it hard to manually define the rules. In our approach, we tackle this problem in a data-driven manner, by automatically learning the conditional distributions using a large scale multimodal social signals corpus.  

Let us denote all types of signals that the target person received in a social situation at time $t$ as $\mathbf{X}(t)$. Thus $\mathbf{X}(t)$ includes the social signals---body gestures, facial expression, body position, voice tones, verbal languages---and other contextual factors such as the space where the conversation is performed or other visible objects which may affect the behavior of the target person (e.g., some sounds or objects may attract the attention of the person). We divide the input signal $\mathbf{X}(t)$ into two parts, the signals from the conversational partners, $\mathbf{X}_c(t)$, and signals from other sources (e.g., objects, environment, and other human subjects not interacting with the target person), $\mathbf{X}_e(t)$.  Thus,
\begin{equation}
\mathbf{X} (t) = \{  \mathbf{X}_c (t), \mathbf{X}_e (t)\}.
\end{equation}
The $\mathbf{X}_c (t)$ may contain social signals from multiple people and we denote the signals from each subject separately:
\begin{equation}
\mathbf{X}_c (t) = \{ \mathbf{X}_c^i (t) \}_{i=1}^N,
\end{equation}
where $\mathbf{X}^i_c (t)$ are the signals from the $i$-th conversational partner in the social interaction and $N$ is the total number of partners. 
Similarly, we denote the signals emitted by the target person at time $t$ in the social situation as $\mathbf{Y} (t)$.
The goal of social signal prediction is to find a function $\mathcal{F}$ which takes $\mathbf{X}$ as input and produces $\mathbf{Y}$ as output to mimic the behavior of the target person in the social situation:
\begin{equation}
\mathbf{Y} (t+1) = \mathcal{F} \left( \mathbf{X} (t_0:t), \mathbf{Y} (t_0:t) \right),
\label{equation:socialPrediction_1}
\end{equation}
where $t_0:t$ represents a range of time from $t_0$ to $t$ affecting the current behavior of the target person. Note that we define the function $\mathcal{F}$ to take the history of the target person's own signals $\mathbf{Y} (t_0:t)$. Intuitively, this formulation models the human behavior as a function that maps the correlation among social signals the target person receiving and emitting. The function can be defined for a specific individual, representing the personal behavior of the target person encoding characteristic, gender, and culture of the target. Based on that, different individuals may behave differently. If the function is regressed by data of many people, then we hypothesize that the function produces more general and common social behaviors, where the person's specific behaviors are averaged out.

Previous approaches can be considered as subsets of this model. For example, conversational agents (or chatbots) using natural language only can be represented as:
\begin{equation}
\mathbf{Y}_v (t+1) =  \mathcal{F} \left( \mathbf{X}_v (t_0:t) \right),
\end{equation}
where $\mathbf{Y}_v$ and $\mathbf{X}_v$ represents only verbal signals. The human motion forecasting studied in computer vision and graphics~\cite{Fragkiadaki_2015_ICCV, jain2016structural} can be considered as:
\begin{equation}
\mathbf{Y}_n (t+1) =  \mathcal{F} \left( \mathbf{Y}_n (t_0:t) \right),
\end{equation}
where $\mathbf{Y}_n$ represents nonverbal body motion. Note that in this task, there is no social interaction modeling, and the prediction is only for an individual using their own previous signals. 

In our work, we focus on nonverbal social signal prediction in a triadic social interaction in the Haggling game scenario:
\begin{equation}
\mathbf{Y} ( t_0:t ) =  \mathcal{F} \left( \mathbf{X}^1 (t_0:t), \mathbf{X}^2 (t_0:t) \right),
\label{equation:F_ours}
\end{equation}
where we predict the social signals of the target person given the signals of the two other people during the same window of time. In particular, we consider diverse input and output social signals to investigate their dynamics and correlations. The details of our approach are described in the following section.

%Modeling rich non-verbal socials (e.g., body motion) among interacting multiple people (more than two) has been rarely studied in previous work.
